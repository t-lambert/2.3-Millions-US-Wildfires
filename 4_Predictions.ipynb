{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4724169,"sourceType":"datasetVersion","datasetId":2733527}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Connect to the database and import the table 'Fires'\nimport os\nimport sqlite3\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nconn = sqlite3.connect('/kaggle/input/us-wildfire-records-6th-edition/data.sqlite') \ndf = pd.read_sql_query('SELECT * FROM Fires;', con=conn)\n\n# Close connection\nconn.close()\n\n# Select only columns of interest\ncol_of_interest = ['OBJECTID', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_DOY', 'NWCG_GENERAL_CAUSE', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE' , 'LONGITUDE' , 'STATE']\ndf = df[col_of_interest].set_index('OBJECTID', verify_integrity = True)\n\n# Rename the columns and the index\ndf = df.rename(columns = {'FIRE_YEAR':'fire_year',\n                         'DISCOVERY_DATE':'disc_date',\n                         'DISCOVERY_DOY':'disc_doy',\n                         'NWCG_GENERAL_CAUSE':'cause',\n                         'FIRE_SIZE' : 'fire_size',\n                         'FIRE_SIZE_CLASS' : 'fire_class',\n                         'LATITUDE':'latitude',\n                         'LONGITUDE':'longitude',\n                         'STATE':'state'}).rename_axis('id')\n\n# Convert the columns 'disc_date' in datetime format and add a colmun with the month\ndf['disc_date'] = pd.to_datetime(pd.to_datetime(df['disc_date'], format = '%m/%d/%Y').dt.strftime('%Y-%m-%d'))\ndf.insert(3, 'disc_month', df['disc_date'].dt.month)\ndf.insert(4, 'disc_day', df['disc_date'].dt.day_name())\n\n# Define a new column 'origin'\nmap_cause = {'Power generation/transmission/distribution':'Accidental',\n            'Natural':'Natural',\n            'Debris and open burning':'Accidental',\n            'Missing data/not specified/undetermined':'Undefined',\n            'Recreation and ceremony':'Accidental',\n            'Equipment and vehicle use':'Accidental',\n            'Arson/incendiarism':'Criminal',\n            'Fireworks':'Accidental',\n            'Other causes':'Accidental',\n            'Railroad operations and maintenance':'Accidental',\n            'Smoking':'Accidental',\n            'Misuse of fire by a minor':'Accidental',\n            'Firearms and explosives use':'Accidental'}\n\ndf['origin'] = df['cause'].map(map_cause)\n\n# For the analysis, we focus on the contiguous USA and define four main geographic area\ndf = df.loc[(df['latitude']>=25) & (df['latitude']<=50)]\n\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T09:52:53.425125Z","iopub.execute_input":"2024-09-20T09:52:53.425671Z","iopub.status.idle":"2024-09-20T09:54:06.932021Z","shell.execute_reply.started":"2024-09-20T09:52:53.425607Z","shell.execute_reply":"2024-09-20T09:54:06.930620Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/us-wildfire-records-6th-edition/_variable_descriptions.csv\n/kaggle/input/us-wildfire-records-6th-edition/data.sqlite\n/kaggle/input/us-wildfire-records-6th-edition/data.csv\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    fire_year  disc_date  disc_doy  disc_month   disc_day  \\\nid                                                          \n1        2005 2005-02-02        33           2  Wednesday   \n2        2004 2004-05-12       133           5  Wednesday   \n3        2004 2004-05-31       152           5     Monday   \n4        2004 2004-06-28       180           6     Monday   \n5        2004 2004-06-28       180           6     Monday   \n\n                                         cause  fire_size fire_class  \\\nid                                                                     \n1   Power generation/transmission/distribution       0.10          A   \n2                                      Natural       0.25          A   \n3                      Debris and open burning       0.10          A   \n4                                      Natural       0.10          A   \n5                                      Natural       0.10          A   \n\n     latitude   longitude state      origin  \nid                                           \n1   40.036944 -121.005833    CA  Accidental  \n2   38.933056 -120.404444    CA     Natural  \n3   38.984167 -120.735556    CA  Accidental  \n4   38.559167 -119.913333    CA     Natural  \n5   38.559167 -119.933056    CA     Natural  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fire_year</th>\n      <th>disc_date</th>\n      <th>disc_doy</th>\n      <th>disc_month</th>\n      <th>disc_day</th>\n      <th>cause</th>\n      <th>fire_size</th>\n      <th>fire_class</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>state</th>\n      <th>origin</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2005</td>\n      <td>2005-02-02</td>\n      <td>33</td>\n      <td>2</td>\n      <td>Wednesday</td>\n      <td>Power generation/transmission/distribution</td>\n      <td>0.10</td>\n      <td>A</td>\n      <td>40.036944</td>\n      <td>-121.005833</td>\n      <td>CA</td>\n      <td>Accidental</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2004</td>\n      <td>2004-05-12</td>\n      <td>133</td>\n      <td>5</td>\n      <td>Wednesday</td>\n      <td>Natural</td>\n      <td>0.25</td>\n      <td>A</td>\n      <td>38.933056</td>\n      <td>-120.404444</td>\n      <td>CA</td>\n      <td>Natural</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2004</td>\n      <td>2004-05-31</td>\n      <td>152</td>\n      <td>5</td>\n      <td>Monday</td>\n      <td>Debris and open burning</td>\n      <td>0.10</td>\n      <td>A</td>\n      <td>38.984167</td>\n      <td>-120.735556</td>\n      <td>CA</td>\n      <td>Accidental</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2004</td>\n      <td>2004-06-28</td>\n      <td>180</td>\n      <td>6</td>\n      <td>Monday</td>\n      <td>Natural</td>\n      <td>0.10</td>\n      <td>A</td>\n      <td>38.559167</td>\n      <td>-119.913333</td>\n      <td>CA</td>\n      <td>Natural</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2004</td>\n      <td>2004-06-28</td>\n      <td>180</td>\n      <td>6</td>\n      <td>Monday</td>\n      <td>Natural</td>\n      <td>0.10</td>\n      <td>A</td>\n      <td>38.559167</td>\n      <td>-119.933056</td>\n      <td>CA</td>\n      <td>Natural</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Summary of the Exploration Data Analysis*\n- \n\n'*' See previous notebook","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import neighbors\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\n\nimport shap","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}}]}